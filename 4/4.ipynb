{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"provenance":[{"file_id":"1d4v390FsxZLuVc0tpJXExU3d21f94VzV","timestamp":1651511974416},{"file_id":"1aJWC1eFfj-fHOql_IpJ50k5hKZNAp0y1","timestamp":1618855088947}],"collapsed_sections":["xP4_qy1yy9bj","bIxsHxttP2k5","i8eluWt3P2lB","jmOeUBmvP2lE","zuDpFWBQ0yWk","LeMxWk5XJISZ","BpdPY3euP59V","-0bX3fgrTaae"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Exercise 4: Using Keras to Build a CIFAR10 CNN\n"],"metadata":{"id":"xP4_qy1yy9bj"}},{"cell_type":"markdown","metadata":{"id":"bIxsHxttP2k5"},"source":["## Building a CNN to classify images in the CIFAR-10 Dataset\n","\n","We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n","\n","The 10 classes are:\n","\n","<ol start=\"0\">\n","<li> airplane\n","<li>  automobile\n","<li> bird\n","<li>  cat\n","<li> deer\n","<li> dog\n","<li>  frog\n","<li>  horse\n","<li>  ship\n","<li>  truck\n","</ol>\n","\n","For details about CIFAR-10 see:\n","https://www.cs.toronto.edu/~kriz/cifar.html\n","\n","For a compilation of published performance results on CIFAR 10, see:\n","http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n","\n","---\n","\n","### Building Convolutional Neural Nets\n","\n","In this exercise we will build and train our first convolutional neural networks.  In the first part, we walk through the different layers and how they are configured.  In the second part, you will build your own model, train it, and compare the performance.\n","\n","Much of this code is from Intel's course at: https://software.intel.com/content/dam/develop/public/us/en/downloads/intel-dl101-class6.zip, but I added some tweaks of my own ;)"]},{"cell_type":"code","metadata":{"id":"eQC8thNfP2k_"},"source":["from __future__ import print_function\n","import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","from tensorflow.python.keras.layers import Input, Dense\n","from tensorflow.keras import layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfQekVzZP2lA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651590540873,"user_tz":-180,"elapsed":928,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"outputId":"6e113e5a-1222-4b80-f29c-1fa03f2eede5"},"source":["# The data, shuffled and split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"]}]},{"cell_type":"code","metadata":{"id":"Nc4W3uKIP2lA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651590540874,"user_tz":-180,"elapsed":7,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"outputId":"43ee6816-ba04-4085-9534-dbf8f91d9b5a"},"source":["## Each image is a 32 x 32 x 3 numpy array\n","x_train[444].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 32, 3)"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"P2OIsQqOnKAN"},"source":["Notice that this time the pictures have color (RGB color with 3 channels)."]},{"cell_type":"code","metadata":{"id":"ePODxy5uP2lA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651590541197,"user_tz":-180,"elapsed":328,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"outputId":"9cf02103-0890-4072-a8db-1883e14bf246"},"source":["## Let's look at one of the images\n","\n","print(y_train[444])\n","plt.imshow(x_train[444]);"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[9]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"czYvqoRAP2lA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651590541198,"user_tz":-180,"elapsed":5,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"outputId":"cd0e8858-1c5f-412f-ce58-95638da7d2f5"},"source":["num_classes = 10\n","print(y_train[444])\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[9]\n"]}]},{"cell_type":"code","metadata":{"id":"srcBlBlVP2lB","executionInfo":{"status":"ok","timestamp":1651590541198,"user_tz":-180,"elapsed":5,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd8e04ec-b388-489b-de4b-da2146d830c1"},"source":["# now instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position\n","y_train[444]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"wSh-NIvhP2lB"},"source":["# As before, let's make everything float and scale\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i8eluWt3P2lB"},"source":["## Keras Layers for CNNs\n","- Previously we built Neural Networks using primarily the Dense, Activation and Dropout Layers.\n","\n","- Here we will describe how to use some of the CNN-specific layers provided by Keras\n","\n","### Conv2D\n","\n","```python\n","keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n","```\n","\n","```python\n","print(\"hi\")\n","```\n","\n","A few parameters explained:\n","- `filters`: the number of filter used per location.  In other words, the depth of the output.\n","- `kernel_size`: an (x,y) tuple giving the height and width of the kernel to be used\n","- `strides`: and (x,y) tuple giving the stride in each dimension.  Default is `(1,1)`\n","- `padding`: With \"SAME\" padding, if you use a stride of 1, the layer's outputs will have the same spatial dimensions as its inputs. (otherwise you will loose size due to the filter)\n","- `input_shape`: required only for the first layer\n","\n","Note, the size of the output will be determined by the kernel_size, strides\n","\n","### MaxPooling2D\n","`keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)`\n","\n","- `pool_size`: the (x,y) size of the grid to be pooled.\n","- `strides`: Assumed to be the `pool_size` unless otherwise specified\n","\n","### Flatten\n","Turns its input into a one-dimensional vector (per instance).  Usually used when transitioning between convolutional layers and fully connected layers.\n","\n","---\n","\n","## First CNN\n","Below we will build our first CNN.  For demonstration purposes (so that it will train quickly) it is not very deep and has relatively few parameters.  We use strides of 2 in the first two convolutional layers which quickly reduces the dimensions of the output.  After a MaxPooling layer, we flatten, and then have a single fully connected layer before our final classification layer."]},{"cell_type":"code","metadata":{"id":"xd7SfmLsP2lC","executionInfo":{"status":"ok","timestamp":1651590541507,"user_tz":-180,"elapsed":9,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d9ba742-7399-43ab-b93a-a85344da5e35"},"source":["# Let's build a CNN using Keras' Sequential capabilities\n","\n","model_1 = Sequential()\n","\n","\n","## 5x5 convolution with 2x2 stride and 32 filters\n","model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',input_shape=(32, 32, 3)))\n","model_1.add(Activation('relu'))\n","\n","## Another 5x5 convolution with 2x2 stride and 32 filters\n","model_1.add(Conv2D(32, (5, 5), strides = (2,2))) \n","model_1.add(Activation('relu'))\n","\n","## 2x2 max pooling reduces to 3 x 3 x 32\n","model_1.add(MaxPooling2D(pool_size=(2, 2)))\n","model_1.add(Dropout(0.25))\n","\n","## Flatten turns 3x3x32 into 288x1\n","model_1.add(Flatten())\n","model_1.add(Dense(512))\n","model_1.add(Activation('relu'))\n","model_1.add(Dropout(0.5))\n","model_1.add(Dense(num_classes))\n","model_1.add(Activation('softmax'))\n","\n","model_1.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_28 (Conv2D)          (None, 16, 16, 32)        2432      \n","                                                                 \n"," activation_42 (Activation)  (None, 16, 16, 32)        0         \n","                                                                 \n"," conv2d_29 (Conv2D)          (None, 6, 6, 32)          25632     \n","                                                                 \n"," activation_43 (Activation)  (None, 6, 6, 32)          0         \n","                                                                 \n"," max_pooling2d_15 (MaxPoolin  (None, 3, 3, 32)         0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_18 (Dropout)        (None, 3, 3, 32)          0         \n","                                                                 \n"," flatten_9 (Flatten)         (None, 288)               0         \n","                                                                 \n"," module_wrapper_16 (ModuleWr  (None, 512)              147968    \n"," apper)                                                          \n","                                                                 \n"," activation_44 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_19 (Dropout)        (None, 512)               0         \n","                                                                 \n"," module_wrapper_17 (ModuleWr  (None, 10)               5130      \n"," apper)                                                          \n","                                                                 \n"," activation_45 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 181,162\n","Trainable params: 181,162\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"hsjjm7nUP2lC"},"source":["We still have 181K parameters, even though this is a \"small\" model.\n","Note that the formula:\n","\n","output_width=(input_width-kernel_width)/stride+1 \n","holds.  For example in the first layer, input_width=32, kernel_width=5 and stride = 2.  So:\n","output_width=32-5/2 = 14 WITHOUT Padding.  But here padding = same, so output = 32/2 (due to stride)= 16. Without stride = 2 it would have been 32 had padding = same.\n","\n","weights=(previous_layer_num_features x kernel_width x kernel_height + b) x filters"]},{"cell_type":"code","metadata":{"id":"TQJhSyUmP2lD","executionInfo":{"status":"ok","timestamp":1651590685303,"user_tz":-180,"elapsed":143799,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"83a987ce-5c95-4c93-898f-6ddede45d759"},"source":["batch_size = 32\n","num_epochs = 10\n","\n","# initiate Adam optimizer like in the first example\n","model_1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","# initiate RMSprop optimizer\n","#opt = keras.optimizers.RMSprop(lr=0.0005, decay=0.00001)\n","\n","# Let's train the model using RMSprop\n","#model_1.compile(loss='categorical_crossentropy',\n","#              optimizer=opt,\n","#              metrics=['accuracy'])\n","\n","model_1.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=num_epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1563/1563 [==============================] - 11s 6ms/step - loss: 1.6673 - accuracy: 0.3908 - val_loss: 1.3721 - val_accuracy: 0.5050\n","Epoch 2/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.3993 - accuracy: 0.4964 - val_loss: 1.2714 - val_accuracy: 0.5443\n","Epoch 3/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.2968 - accuracy: 0.5354 - val_loss: 1.1935 - val_accuracy: 0.5673\n","Epoch 4/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.2354 - accuracy: 0.5574 - val_loss: 1.1132 - val_accuracy: 0.6118\n","Epoch 5/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.1801 - accuracy: 0.5806 - val_loss: 1.1152 - val_accuracy: 0.6079\n","Epoch 6/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.1470 - accuracy: 0.5915 - val_loss: 1.0711 - val_accuracy: 0.6295\n","Epoch 7/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.1164 - accuracy: 0.6015 - val_loss: 1.0366 - val_accuracy: 0.6358\n","Epoch 8/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.0888 - accuracy: 0.6133 - val_loss: 1.0043 - val_accuracy: 0.6441\n","Epoch 9/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.0728 - accuracy: 0.6201 - val_loss: 1.0208 - val_accuracy: 0.6423\n","Epoch 10/10\n","1563/1563 [==============================] - 10s 6ms/step - loss: 1.0586 - accuracy: 0.6263 - val_loss: 1.0048 - val_accuracy: 0.6477\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f56cffd8f90>"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"dOy-IQMuU4l0"},"source":["## Evaluate the trained model"]},{"cell_type":"code","metadata":{"id":"3Z8y3b2GU4l1","executionInfo":{"status":"ok","timestamp":1651590686396,"user_tz":-180,"elapsed":1113,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef21cd98-b60e-4d79-d5d6-9bd37b2596a8"},"source":["score = model_1.evaluate(x_test, y_test, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 1.0047708749771118\n","Test accuracy: 0.6477000117301941\n"]}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"jmOeUBmvP2lE"},"source":["### Exercise\n","There are many things we can change in CNNs:\n","1. The batch size\n","2. The parameters within a specific CNN layer such as if padding is used, the size (kernel size) and number of filters used, and stride size\n","3. The Dropout rate (if any) that is used\n","4. The CNN architecture including the number of layers and if and when to use MaxPool (AvgPool usually isn't used today).\n","5. The optimizer used (and the learning rate in the optimizer)\n","6. In theory which activation function, but in CNN's Relu is almost always used except for the last layer which is Softmax (which activation function is Softmax???)\n","\n","Questions: \n","\n","A. Build model_2 which checks the performance of batch sizes of 4, 128 and 1024.  Which one works best after 10 epochs?  Which one runs the fastest?\n","\n","B. Build model_3 which adds padding to all layers. Does that improve performance?\n","\n","C. Build model_4 which uses the same architecture from the MNIST network. Does that work better?\n","\n","D. Build model_5 which adds to the structure of model_1-- either by adding more convolution layers or Maxpool layers.   Intel suggests trying the architecture: \n","\n","Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n","\n","instead of:\n","\n","Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n","\n","If you do this, you will likely need to lower the stride to 1 as otherwise the layers are not big enough in this dataset!\n","\n","Please run the network that worked the best for more than 10 epochs and see how good you get!\n","\n","Hint:  Feel free to work on different colab notebooks in parallel (Google doesn't care until around 5 at the same time) and / or run the code on your computer and then paste it back to Colab when you are done (the code works faster on my computer than in Colab but everyone's computer is different).\n","\n","Your grade is based on the following:\n","\n","80 points for correctly doing all questions and documenting your solution including the answers to the my questions.\n","\n","5 points for breaking 65% accuracy in your best model\n","\n","10 points for breaking 70% accuracy in your best model\n","\n","3 points for breaking 72% accuracy in your best model\n","\n","2 points for breaking 75% accuracy in your best model"]},{"cell_type":"markdown","source":["## Question A: "],"metadata":{"id":"zuDpFWBQ0yWk"}},{"cell_type":"markdown","source":["Build model_2 which checks the performance of batch sizes of 4, 128 and 1024. "],"metadata":{"id":"u814jJti1Gyl"}},{"cell_type":"code","source":["def cnn_model2(batch_size):\n","\n","  start = datetime.now()\n","\n","  model_2 = Sequential()\n","\n","  ## 5x5 convolution with 2x2 stride and 32 filters\n","  model_2.add(Conv2D(32, (5, 5), strides = (2, 2), padding = 'same', input_shape = x_train.shape[1:]))\n","  model_2.add(Activation('relu'))\n","\n","  ## Another 5x5 convolution with 2x2 stride and 32 filters\n","  model_2.add(Conv2D(32, (5, 5), strides = (2, 2))) \n","  model_2.add(Activation('relu'))\n","\n","  ## 2x2 max pooling reduces to 3 x 3 x 32\n","  model_2.add(MaxPooling2D(pool_size = (2, 2)))\n","  model_2.add(Dropout(0.25))\n","\n","  ## Flatten turns 3x3x32 into 288x1\n","  model_2.add(Flatten())\n","\n","  model_2.add(Dense(512))\n","  model_2.add(Activation('relu'))\n","\n","  model_2.add(Dropout(0.5))\n","\n","  model_2.add(Dense(num_classes))\n","  model_2.add(Activation('softmax'))\n","\n","  model_2.summary()\n","\n","  model_2.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","  model_2.fit(x_train, y_train,batch_size = batch_size, epochs = 10, validation_data = (x_test, y_test), shuffle = True)\n","\n","  score = model_2.evaluate(x_test, y_test, verbose = 0)\n","  return(score[0], score[1], datetime.now() - start)"],"metadata":{"id":"94ztXulx0qoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_model_2 = {4 : cnn_model2(4), 128 : cnn_model2(128), 1024 : cnn_model2(1024)} #dictionary with the batch size as keys and the results of the models as values."],"metadata":{"id":"7Y1e1H4d0wRu","executionInfo":{"status":"ok","timestamp":1651591434342,"user_tz":-180,"elapsed":747954,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0677f149-12b4-496f-a18b-8506c95db5f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_30 (Conv2D)          (None, 16, 16, 32)        2432      \n","                                                                 \n"," activation_46 (Activation)  (None, 16, 16, 32)        0         \n","                                                                 \n"," conv2d_31 (Conv2D)          (None, 6, 6, 32)          25632     \n","                                                                 \n"," activation_47 (Activation)  (None, 6, 6, 32)          0         \n","                                                                 \n"," max_pooling2d_16 (MaxPoolin  (None, 3, 3, 32)         0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_20 (Dropout)        (None, 3, 3, 32)          0         \n","                                                                 \n"," flatten_10 (Flatten)        (None, 288)               0         \n","                                                                 \n"," module_wrapper_18 (ModuleWr  (None, 512)              147968    \n"," apper)                                                          \n","                                                                 \n"," activation_48 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_21 (Dropout)        (None, 512)               0         \n","                                                                 \n"," module_wrapper_19 (ModuleWr  (None, 10)               5130      \n"," apper)                                                          \n","                                                                 \n"," activation_49 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 181,162\n","Trainable params: 181,162\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","12500/12500 [==============================] - 63s 5ms/step - loss: 1.7556 - accuracy: 0.3521 - val_loss: 1.5050 - val_accuracy: 0.4515\n","Epoch 2/10\n","12500/12500 [==============================] - 61s 5ms/step - loss: 1.5690 - accuracy: 0.4286 - val_loss: 1.3793 - val_accuracy: 0.4981\n","Epoch 3/10\n","12500/12500 [==============================] - 66s 5ms/step - loss: 1.5266 - accuracy: 0.4501 - val_loss: 1.3896 - val_accuracy: 0.4999\n","Epoch 4/10\n","12500/12500 [==============================] - 61s 5ms/step - loss: 1.4953 - accuracy: 0.4639 - val_loss: 1.3727 - val_accuracy: 0.5094\n","Epoch 5/10\n","12500/12500 [==============================] - 66s 5ms/step - loss: 1.4905 - accuracy: 0.4662 - val_loss: 1.3946 - val_accuracy: 0.5033\n","Epoch 6/10\n","12500/12500 [==============================] - 66s 5ms/step - loss: 1.4806 - accuracy: 0.4704 - val_loss: 1.3999 - val_accuracy: 0.5028\n","Epoch 7/10\n","12500/12500 [==============================] - 61s 5ms/step - loss: 1.4733 - accuracy: 0.4721 - val_loss: 1.5041 - val_accuracy: 0.4747\n","Epoch 8/10\n","12500/12500 [==============================] - 66s 5ms/step - loss: 1.4667 - accuracy: 0.4752 - val_loss: 1.3682 - val_accuracy: 0.5194\n","Epoch 9/10\n","12500/12500 [==============================] - 62s 5ms/step - loss: 1.4633 - accuracy: 0.4787 - val_loss: 1.3610 - val_accuracy: 0.5190\n","Epoch 10/10\n","12500/12500 [==============================] - 66s 5ms/step - loss: 1.4585 - accuracy: 0.4849 - val_loss: 1.3480 - val_accuracy: 0.5274\n","Model: \"sequential_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_32 (Conv2D)          (None, 16, 16, 32)        2432      \n","                                                                 \n"," activation_50 (Activation)  (None, 16, 16, 32)        0         \n","                                                                 \n"," conv2d_33 (Conv2D)          (None, 6, 6, 32)          25632     \n","                                                                 \n"," activation_51 (Activation)  (None, 6, 6, 32)          0         \n","                                                                 \n"," max_pooling2d_17 (MaxPoolin  (None, 3, 3, 32)         0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_22 (Dropout)        (None, 3, 3, 32)          0         \n","                                                                 \n"," flatten_11 (Flatten)        (None, 288)               0         \n","                                                                 \n"," module_wrapper_20 (ModuleWr  (None, 512)              147968    \n"," apper)                                                          \n","                                                                 \n"," activation_52 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_23 (Dropout)        (None, 512)               0         \n","                                                                 \n"," module_wrapper_21 (ModuleWr  (None, 10)               5130      \n"," apper)                                                          \n","                                                                 \n"," activation_53 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 181,162\n","Trainable params: 181,162\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 5s 11ms/step - loss: 1.7425 - accuracy: 0.3626 - val_loss: 1.4383 - val_accuracy: 0.4843\n","Epoch 2/10\n","391/391 [==============================] - 4s 9ms/step - loss: 1.4614 - accuracy: 0.4729 - val_loss: 1.2962 - val_accuracy: 0.5442\n","Epoch 3/10\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3502 - accuracy: 0.5156 - val_loss: 1.2374 - val_accuracy: 0.5641\n","Epoch 4/10\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2873 - accuracy: 0.5419 - val_loss: 1.1992 - val_accuracy: 0.5701\n","Epoch 5/10\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2376 - accuracy: 0.5564 - val_loss: 1.1197 - val_accuracy: 0.6017\n","Epoch 6/10\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1965 - accuracy: 0.5721 - val_loss: 1.1146 - val_accuracy: 0.6051\n","Epoch 7/10\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1704 - accuracy: 0.5812 - val_loss: 1.0779 - val_accuracy: 0.6216\n","Epoch 8/10\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1419 - accuracy: 0.5922 - val_loss: 1.0407 - val_accuracy: 0.6332\n","Epoch 9/10\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1206 - accuracy: 0.6020 - val_loss: 1.0314 - val_accuracy: 0.6418\n","Epoch 10/10\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1006 - accuracy: 0.6075 - val_loss: 1.0129 - val_accuracy: 0.6441\n","Model: \"sequential_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_34 (Conv2D)          (None, 16, 16, 32)        2432      \n","                                                                 \n"," activation_54 (Activation)  (None, 16, 16, 32)        0         \n","                                                                 \n"," conv2d_35 (Conv2D)          (None, 6, 6, 32)          25632     \n","                                                                 \n"," activation_55 (Activation)  (None, 6, 6, 32)          0         \n","                                                                 \n"," max_pooling2d_18 (MaxPoolin  (None, 3, 3, 32)         0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_24 (Dropout)        (None, 3, 3, 32)          0         \n","                                                                 \n"," flatten_12 (Flatten)        (None, 288)               0         \n","                                                                 \n"," module_wrapper_22 (ModuleWr  (None, 512)              147968    \n"," apper)                                                          \n","                                                                 \n"," activation_56 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_25 (Dropout)        (None, 512)               0         \n","                                                                 \n"," module_wrapper_23 (ModuleWr  (None, 10)               5130      \n"," apper)                                                          \n","                                                                 \n"," activation_57 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 181,162\n","Trainable params: 181,162\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","49/49 [==============================] - 3s 44ms/step - loss: 2.0383 - accuracy: 0.2504 - val_loss: 1.7311 - val_accuracy: 0.3816\n","Epoch 2/10\n","49/49 [==============================] - 2s 34ms/step - loss: 1.6731 - accuracy: 0.3933 - val_loss: 1.5139 - val_accuracy: 0.4522\n","Epoch 3/10\n","49/49 [==============================] - 2s 33ms/step - loss: 1.5338 - accuracy: 0.4409 - val_loss: 1.4356 - val_accuracy: 0.4808\n","Epoch 4/10\n","49/49 [==============================] - 2s 33ms/step - loss: 1.4820 - accuracy: 0.4626 - val_loss: 1.3916 - val_accuracy: 0.5018\n","Epoch 5/10\n","49/49 [==============================] - 2s 33ms/step - loss: 1.4194 - accuracy: 0.4856 - val_loss: 1.3383 - val_accuracy: 0.5225\n","Epoch 6/10\n","49/49 [==============================] - 2s 33ms/step - loss: 1.3731 - accuracy: 0.5039 - val_loss: 1.2908 - val_accuracy: 0.5469\n","Epoch 7/10\n","49/49 [==============================] - 2s 33ms/step - loss: 1.3301 - accuracy: 0.5203 - val_loss: 1.2706 - val_accuracy: 0.5468\n","Epoch 8/10\n","49/49 [==============================] - 2s 33ms/step - loss: 1.3064 - accuracy: 0.5327 - val_loss: 1.2217 - val_accuracy: 0.5657\n","Epoch 9/10\n","49/49 [==============================] - 2s 34ms/step - loss: 1.2729 - accuracy: 0.5452 - val_loss: 1.1894 - val_accuracy: 0.5785\n","Epoch 10/10\n","49/49 [==============================] - 2s 33ms/step - loss: 1.2535 - accuracy: 0.5521 - val_loss: 1.1671 - val_accuracy: 0.5857\n"]}]},{"cell_type":"code","source":["# for bold text: ('\\033[1m' + 'Text' + '\\033[0m')\n","\n","print('\\033[1mFor batch_size = 4:\\033[0m loss is {:.3f}, the accuracy is {:.3f} and the run time was {:.1f} minutes'.format(results_model_2[4][0],results_model_2[4][1],results_model_2[4][2].seconds/60))\n","print('\\033[1mFor batch_size = 128:\\033[0m loss is {:.3f}, the accuracy is {:.3f} and the run time was {:.1f} minutes'.format(results_model_2[128][0],results_model_2[128][1],results_model_2[128][2].seconds/60))\n","print('\\033[1mFor batch_size = 1024:\\033[0m loss is {:.3f}, the accuracy is {:.3f} and the run time was {:.1f} minutes'.format(results_model_2[1024][0],results_model_2[1024][1],results_model_2[1024][2].seconds/60))\n","\n","best_acc_batch_size = max(results_model_2, key = lambda x: results_model_2[x][1]) # the batch size with the best accuravy\n","best_runtime_batch_size = min(results_model_2, key = lambda x: results_model_2[x][2]) # the batch size with the best runtime\n","\n","print(('\\n\\033[1mFor batch_size = {:d} we got the best accuracy: {:.3f}'.format(best_acc_batch_size,results_model_2[best_acc_batch_size][1]))+'\\033[0m')\n","print(('\\033[1mFor batch_size = {:d} we got the shortest runtime: {:.1f}'.format(best_runtime_batch_size,results_model_2[best_runtime_batch_size][2].seconds/60))+'\\033[0m')\n","\n","accuracy_A = results_model_2[best_acc_batch_size][1]"],"metadata":{"id":"QOLLO8-s521_","executionInfo":{"status":"ok","timestamp":1651591434343,"user_tz":-180,"elapsed":26,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"64cd9274-f535-46f6-e21e-ce12bc08b01c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mFor batch_size = 4:\u001b[0m loss is 1.348, the accuracy is 0.527 and the run time was 11.4 minutes\n","\u001b[1mFor batch_size = 128:\u001b[0m loss is 1.013, the accuracy is 0.644 and the run time was 0.7 minutes\n","\u001b[1mFor batch_size = 1024:\u001b[0m loss is 1.167, the accuracy is 0.586 and the run time was 0.3 minutes\n","\n","\u001b[1mFor batch_size = 128 we got the best accuracy: 0.644\u001b[0m\n","\u001b[1mFor batch_size = 1024 we got the shortest runtime: 0.3\u001b[0m\n"]}]},{"cell_type":"markdown","source":["## Question B:"],"metadata":{"id":"LeMxWk5XJISZ"}},{"cell_type":"markdown","source":["Build model_3 which adds padding to all layers. "],"metadata":{"id":"5fmVxqaoJUP4"}},{"cell_type":"code","source":["#we chose the batch size with the best accuracy:\n","batch_size = best_acc_batch_size\n","\n","model_3 = Sequential()\n","\n","## 5x5 convolution with 2x2 stride and 32 filters\n","model_3.add(Conv2D(32, (5, 5), strides = (2, 2), padding = 'same', input_shape = x_train.shape[1:]))\n","model_3.add(Activation('relu'))\n","\n","## Another 5x5 convolution with 2x2 stride and 32 filters\n","model_3.add(Conv2D(32, (5, 5), strides = (2, 2), padding = 'same')) \n","model_3.add(Activation('relu'))\n","\n","## 2x2 max pooling reduces to 3 x 3 x 32\n","model_3.add(MaxPooling2D(pool_size = (2, 2), padding = 'same'))\n","model_3.add(Dropout(0.25))\n","\n","## Flatten turns 3x3x32 into 288x1\n","model_3.add(Flatten())\n","\n","model_3.add(Dense(512))\n","model_3.add(Activation('relu'))\n","\n","model_3.add(Dropout(0.5))\n","\n","model_3.add(Dense(num_classes))\n","model_3.add(Activation('softmax'))\n","\n","model_3.summary()\n","\n","model_3.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","model_3.fit(x_train, y_train, batch_size = batch_size, epochs = 10, validation_data = (x_test, y_test), shuffle = True)"],"metadata":{"id":"1eWyFoZ1JPDs","executionInfo":{"status":"ok","timestamp":1651591478065,"user_tz":-180,"elapsed":43733,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d9452be-d86d-4dd3-c3fa-b16ee082632b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_13\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_36 (Conv2D)          (None, 16, 16, 32)        2432      \n","                                                                 \n"," activation_58 (Activation)  (None, 16, 16, 32)        0         \n","                                                                 \n"," conv2d_37 (Conv2D)          (None, 8, 8, 32)          25632     \n","                                                                 \n"," activation_59 (Activation)  (None, 8, 8, 32)          0         \n","                                                                 \n"," max_pooling2d_19 (MaxPoolin  (None, 4, 4, 32)         0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_26 (Dropout)        (None, 4, 4, 32)          0         \n","                                                                 \n"," flatten_13 (Flatten)        (None, 512)               0         \n","                                                                 \n"," module_wrapper_24 (ModuleWr  (None, 512)              262656    \n"," apper)                                                          \n","                                                                 \n"," activation_60 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_27 (Dropout)        (None, 512)               0         \n","                                                                 \n"," module_wrapper_25 (ModuleWr  (None, 10)               5130      \n"," apper)                                                          \n","                                                                 \n"," activation_61 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 295,850\n","Trainable params: 295,850\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 5s 12ms/step - loss: 1.6920 - accuracy: 0.3844 - val_loss: 1.4322 - val_accuracy: 0.4865\n","Epoch 2/10\n","391/391 [==============================] - 4s 10ms/step - loss: 1.4069 - accuracy: 0.4950 - val_loss: 1.2547 - val_accuracy: 0.5606\n","Epoch 3/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2888 - accuracy: 0.5396 - val_loss: 1.1582 - val_accuracy: 0.5923\n","Epoch 4/10\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2174 - accuracy: 0.5685 - val_loss: 1.1442 - val_accuracy: 0.5979\n","Epoch 5/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1638 - accuracy: 0.5860 - val_loss: 1.0587 - val_accuracy: 0.6288\n","Epoch 6/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1138 - accuracy: 0.6050 - val_loss: 1.0529 - val_accuracy: 0.6325\n","Epoch 7/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.0707 - accuracy: 0.6190 - val_loss: 1.0012 - val_accuracy: 0.6532\n","Epoch 8/10\n","391/391 [==============================] - 4s 10ms/step - loss: 1.0397 - accuracy: 0.6305 - val_loss: 0.9719 - val_accuracy: 0.6635\n","Epoch 9/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.0049 - accuracy: 0.6445 - val_loss: 0.9506 - val_accuracy: 0.6646\n","Epoch 10/10\n","391/391 [==============================] - 4s 10ms/step - loss: 0.9809 - accuracy: 0.6542 - val_loss: 0.9460 - val_accuracy: 0.6744\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f56cfa65bd0>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["score = model_3.evaluate(x_test, y_test, verbose = 0)\n","accuracy_B = score[1]\n","\n","print(('\\033[1mTest loss:\\033[0m {:.3f}').format(score[0]))\n","print(('\\033[1mTest accuracy:\\033[0m {:.3f}').format(accuracy_B))\n","print('\\n\\033[1mDid padding improve the performance?\\033[0m', accuracy_B > accuracy_A)"],"metadata":{"id":"vRGkjPIRJ5CO","executionInfo":{"status":"ok","timestamp":1651591479587,"user_tz":-180,"elapsed":1533,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0de9a1f-97ae-4abb-8f70-7c1e317bf6dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mTest loss:\u001b[0m 0.946\n","\u001b[1mTest accuracy:\u001b[0m 0.674\n","\n","\u001b[1mDid padding improve the performance?\u001b[0m True\n"]}]},{"cell_type":"markdown","source":["## Question C:"],"metadata":{"id":"BpdPY3euP59V"}},{"cell_type":"markdown","source":["Build model_4 which uses the same architecture from the MNIST network."],"metadata":{"id":"7m_rDTcEQA-T"}},{"cell_type":"code","source":["model_4 = keras.Sequential(\n","    [\n","        keras.Input(shape=x_train.shape[1:]),\n","        tf.keras.layers.Conv2D(32, kernel_size = (3, 3), activation = \"relu\"),\n","        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n","        tf.keras.layers.Conv2D(64, kernel_size = (3, 3), activation = \"relu\"),\n","        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(num_classes, activation = \"softmax\"),\n","    ]\n",")\n","\n","model_4.summary()\n","\n","model_4.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","model_4.fit(x_train, y_train, batch_size = batch_size, epochs = 10, validation_data = (x_test, y_test), shuffle = True)"],"metadata":{"id":"RFjdbrIkQv2w","executionInfo":{"status":"ok","timestamp":1651591524878,"user_tz":-180,"elapsed":45298,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"62c445c2-9fb1-4ce0-ee91-911899b5b5c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_14\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_38 (Conv2D)          (None, 30, 30, 32)        896       \n","                                                                 \n"," max_pooling2d_20 (MaxPoolin  (None, 15, 15, 32)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_39 (Conv2D)          (None, 13, 13, 64)        18496     \n","                                                                 \n"," max_pooling2d_21 (MaxPoolin  (None, 6, 6, 64)         0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_14 (Flatten)        (None, 2304)              0         \n","                                                                 \n"," dropout_28 (Dropout)        (None, 2304)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                23050     \n","                                                                 \n","=================================================================\n","Total params: 42,442\n","Trainable params: 42,442\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 5s 13ms/step - loss: 1.7393 - accuracy: 0.3738 - val_loss: 1.4924 - val_accuracy: 0.4785\n","Epoch 2/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.4216 - accuracy: 0.4936 - val_loss: 1.2901 - val_accuracy: 0.5489\n","Epoch 3/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3130 - accuracy: 0.5360 - val_loss: 1.2449 - val_accuracy: 0.5569\n","Epoch 4/10\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2377 - accuracy: 0.5648 - val_loss: 1.1514 - val_accuracy: 0.5995\n","Epoch 5/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1850 - accuracy: 0.5864 - val_loss: 1.1107 - val_accuracy: 0.6140\n","Epoch 6/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1433 - accuracy: 0.5996 - val_loss: 1.0682 - val_accuracy: 0.6299\n","Epoch 7/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1035 - accuracy: 0.6150 - val_loss: 1.0107 - val_accuracy: 0.6486\n","Epoch 8/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.0760 - accuracy: 0.6272 - val_loss: 1.0061 - val_accuracy: 0.6549\n","Epoch 9/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.0518 - accuracy: 0.6335 - val_loss: 0.9772 - val_accuracy: 0.6691\n","Epoch 10/10\n","391/391 [==============================] - 4s 11ms/step - loss: 1.0329 - accuracy: 0.6413 - val_loss: 0.9755 - val_accuracy: 0.6704\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f56d18cd490>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["score = model_4.evaluate(x_test, y_test, verbose = 0)\n","accuracy_C = score[1]\n","\n","print(('\\033[1mTest loss:\\033[0m {:.3f}').format(score[0]))\n","print(('\\033[1mTest accuracy:\\033[0m {:.3f}').format(accuracy_C))\n","print('\\n\\033[1mDid it work better?\\033[0m', accuracy_C > accuracy_B)"],"metadata":{"id":"o2nGKaJ2StGw","executionInfo":{"status":"ok","timestamp":1651591526004,"user_tz":-180,"elapsed":1138,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"175c674b-d3e2-487c-f5fc-b336294726cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mTest loss:\u001b[0m 0.975\n","\u001b[1mTest accuracy:\u001b[0m 0.670\n","\n","\u001b[1mDid it work better?\u001b[0m False\n"]}]},{"cell_type":"markdown","source":["## Question D:"],"metadata":{"id":"-0bX3fgrTaae"}},{"cell_type":"markdown","source":["Build model_5 which adds to the structure of model_1 - either by adding more convolution layers or Maxpool layers."],"metadata":{"id":"9QOqKw_lTjYL"}},{"cell_type":"markdown","source":["**First, we try Intel suggestion:**\n","\n","Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification"],"metadata":{"id":"A17-R-WnZBYg"}},{"cell_type":"code","source":["model_5 = Sequential()\n","\n","## 5x5 convolution with 1x1 stride and 32 filters\n","model_5.add(Conv2D(32, (5, 5), strides = (1, 1), padding = 'same', input_shape = image_batch_train.shape))\n","model_5.add(Activation('relu'))\n","\n","## Another 5x5 convolution with 1x1 stride and 32 filters\n","model_5.add(Conv2D(32, (5, 5), strides = (1, 1))) \n","model_5.add(Activation('relu'))\n","\n","## 2x2 max pooling\n","model_5.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","# Dropout by 0.25\n","model_5.add(Dropout(0.25))\n","\n","## 5x5 convolution with 2x2 stride and 32 filters\n","model_5.add(Conv2D(32, (5, 5), strides = (2, 2), padding = 'same'))\n","model_5.add(Activation('relu'))\n","\n","## 3x3 convolution with 2x2 stride and 16 filters\n","model_5.add(Conv2D(16, (3, 3), strides = (2, 2))) \n","model_5.add(Activation('relu'))\n","\n","## 2x2 max pooling\n","model_5.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","# Dropout by 0.25\n","model_5.add(Dropout(0.25))\n","\n","# Flatten\n","model_5.add(Flatten())\n","\n","# Dense\n","model_5.add(Dense(512))\n","model_5.add(Activation('relu'))\n","\n","# Dropout by 0.5\n","model_5.add(Dropout(0.5))\n","\n","# Final dense\n","model_5.add(Dense(num_classes))\n","model_5.add(Activation('softmax'))\n","\n","model_5.summary()\n","\n","model_5.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","model_5.fit(x_train, y_train, batch_size = 32, epochs = 10, validation_data = (x_test, y_test), shuffle = True)"],"metadata":{"id":"-KEqedxuUJgV","executionInfo":{"status":"ok","timestamp":1651591711787,"user_tz":-180,"elapsed":185786,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"42931957-1d40-46f0-b18b-6ea09ce381f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_15\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_40 (Conv2D)          (None, 32, 32, 32)        2432      \n","                                                                 \n"," activation_62 (Activation)  (None, 32, 32, 32)        0         \n","                                                                 \n"," conv2d_41 (Conv2D)          (None, 28, 28, 32)        25632     \n","                                                                 \n"," activation_63 (Activation)  (None, 28, 28, 32)        0         \n","                                                                 \n"," max_pooling2d_22 (MaxPoolin  (None, 14, 14, 32)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_29 (Dropout)        (None, 14, 14, 32)        0         \n","                                                                 \n"," conv2d_42 (Conv2D)          (None, 7, 7, 32)          25632     \n","                                                                 \n"," activation_64 (Activation)  (None, 7, 7, 32)          0         \n","                                                                 \n"," conv2d_43 (Conv2D)          (None, 3, 3, 16)          4624      \n","                                                                 \n"," activation_65 (Activation)  (None, 3, 3, 16)          0         \n","                                                                 \n"," max_pooling2d_23 (MaxPoolin  (None, 1, 1, 16)         0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_30 (Dropout)        (None, 1, 1, 16)          0         \n","                                                                 \n"," flatten_15 (Flatten)        (None, 16)                0         \n","                                                                 \n"," module_wrapper_26 (ModuleWr  (None, 512)              8704      \n"," apper)                                                          \n","                                                                 \n"," activation_66 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_31 (Dropout)        (None, 512)               0         \n","                                                                 \n"," module_wrapper_27 (ModuleWr  (None, 10)               5130      \n"," apper)                                                          \n","                                                                 \n"," activation_67 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 72,154\n","Trainable params: 72,154\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1563/1563 [==============================] - 20s 12ms/step - loss: 1.9498 - accuracy: 0.2602 - val_loss: 1.6534 - val_accuracy: 0.3962\n","Epoch 2/10\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.6753 - accuracy: 0.3723 - val_loss: 1.5482 - val_accuracy: 0.4373\n","Epoch 3/10\n","1563/1563 [==============================] - 18s 12ms/step - loss: 1.5831 - accuracy: 0.4085 - val_loss: 1.4353 - val_accuracy: 0.4771\n","Epoch 4/10\n","1563/1563 [==============================] - 20s 13ms/step - loss: 1.5247 - accuracy: 0.4311 - val_loss: 1.3892 - val_accuracy: 0.4944\n","Epoch 5/10\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.4738 - accuracy: 0.4545 - val_loss: 1.4835 - val_accuracy: 0.4733\n","Epoch 6/10\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.4337 - accuracy: 0.4707 - val_loss: 1.3539 - val_accuracy: 0.5166\n","Epoch 7/10\n","1563/1563 [==============================] - 19s 12ms/step - loss: 1.4009 - accuracy: 0.4886 - val_loss: 1.2932 - val_accuracy: 0.5388\n","Epoch 8/10\n","1563/1563 [==============================] - 18s 11ms/step - loss: 1.3734 - accuracy: 0.4963 - val_loss: 1.2934 - val_accuracy: 0.5428\n","Epoch 9/10\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3539 - accuracy: 0.5082 - val_loss: 1.2984 - val_accuracy: 0.5428\n","Epoch 10/10\n","1563/1563 [==============================] - 17s 11ms/step - loss: 1.3311 - accuracy: 0.5176 - val_loss: 1.2205 - val_accuracy: 0.5696\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f56d17c5550>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["score = model_5.evaluate(x_test, y_test, verbose = 0)\n","accuracy_D = score[1]\n","\n","print(('\\033[1mTest loss:\\033[0m {:.3f}').format(score[0]))\n","print(('\\033[1mTest accuracy:\\033[0m {:.3f}').format(accuracy_D))\n","print('\\n\\033[1mDid it work better?\\033[0m', accuracy_D > accuracy_C)"],"metadata":{"id":"jJVKRjRvUFw2","executionInfo":{"status":"ok","timestamp":1651591714533,"user_tz":-180,"elapsed":2781,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"69dd04cb-969f-4253-c7ed-c263034582ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mTest loss:\u001b[0m 1.220\n","\u001b[1mTest accuracy:\u001b[0m 0.570\n","\n","\u001b[1mDid it work better?\u001b[0m False\n"]}]},{"cell_type":"markdown","source":["**Second, we try to add more layers and to change parameters, to improve the model accuracy:**\n","\n","Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification"],"metadata":{"id":"qIDEH7ioZbgP"}},{"cell_type":"code","source":["model_5 = Sequential()\n","\n","## 3x3 convolution with 1x1 stride (default) and 32 filters\n","model_5.add(Conv2D(32, (3, 3), padding = 'same', input_shape = x_train.shape[1:]))\n","model_5.add(Activation('relu'))\n","\n","## 3x3 convolution with 1x1 stride (default) and 32 filters\n","model_5.add(Conv2D(32, (3, 3), padding = 'same'))\n","model_5.add(Activation('relu'))\n","\n","## 2x2 max pooling\n","model_5.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","## 3x3 convolution with 1x1 stride (default) and 64 filters\n","model_5.add(Conv2D(64, (3, 3), padding = 'same'))\n","model_5.add(Activation('relu'))\n","\n","## 3x3 convolution with 1x1 stride (default) and 64 filters\n","model_5.add(Conv2D(64, (3, 3), padding = 'same'))\n","model_5.add(Activation('relu'))\n","\n","## 2x2 max pooling\n","model_5.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","## 3x3 convolution with 1x1 stride (default) and 128 filters\n","model_5.add(Conv2D(128, (3, 3), padding = 'same'))\n","model_5.add(Activation('relu'))\n","\n","## 3x3 convolution with 1x1 stride (default) and 128 filters\n","model_5.add(Conv2D(128, (3, 3), padding = 'same'))\n","model_5.add(Activation('relu'))\n","\n","## 2x2 max pooling\n","model_5.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","# Flatten\n","model_5.add(Flatten())\n","\n","# Dropout by 0.25\n","model_5.add(Dropout(0.25))\n","\n","# Dense\n","model_5.add(Dense(1024))\n","model_5.add(Activation('relu'))\n","\n","# Dropout by 0.5\n","model_5.add(Dropout(0.5))\n","\n","# Final dense\n","model_5.add(Dense(num_classes))\n","model_5.add(Activation('softmax'))\n","\n","model_5.summary()\n","\n","model_5.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","model_5.fit(x_train, y_train, batch_size = 32, epochs = 10, validation_data = (x_test, y_test), shuffle = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fkDUtEnZLXNg","executionInfo":{"status":"ok","timestamp":1651592038481,"user_tz":-180,"elapsed":323956,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"outputId":"73de274f-9e68-40c2-96c1-974c5ffecd2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_44 (Conv2D)          (None, 32, 32, 32)        896       \n","                                                                 \n"," activation_68 (Activation)  (None, 32, 32, 32)        0         \n","                                                                 \n"," conv2d_45 (Conv2D)          (None, 32, 32, 32)        9248      \n","                                                                 \n"," activation_69 (Activation)  (None, 32, 32, 32)        0         \n","                                                                 \n"," max_pooling2d_24 (MaxPoolin  (None, 16, 16, 32)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_46 (Conv2D)          (None, 16, 16, 64)        18496     \n","                                                                 \n"," activation_70 (Activation)  (None, 16, 16, 64)        0         \n","                                                                 \n"," conv2d_47 (Conv2D)          (None, 16, 16, 64)        36928     \n","                                                                 \n"," activation_71 (Activation)  (None, 16, 16, 64)        0         \n","                                                                 \n"," max_pooling2d_25 (MaxPoolin  (None, 8, 8, 64)         0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_48 (Conv2D)          (None, 8, 8, 128)         73856     \n","                                                                 \n"," activation_72 (Activation)  (None, 8, 8, 128)         0         \n","                                                                 \n"," conv2d_49 (Conv2D)          (None, 8, 8, 128)         147584    \n","                                                                 \n"," activation_73 (Activation)  (None, 8, 8, 128)         0         \n","                                                                 \n"," max_pooling2d_26 (MaxPoolin  (None, 4, 4, 128)        0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_16 (Flatten)        (None, 2048)              0         \n","                                                                 \n"," dropout_32 (Dropout)        (None, 2048)              0         \n","                                                                 \n"," module_wrapper_28 (ModuleWr  (None, 1024)             2098176   \n"," apper)                                                          \n","                                                                 \n"," activation_74 (Activation)  (None, 1024)              0         \n","                                                                 \n"," dropout_33 (Dropout)        (None, 1024)              0         \n","                                                                 \n"," module_wrapper_29 (ModuleWr  (None, 10)               10250     \n"," apper)                                                          \n","                                                                 \n"," activation_75 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 2,395,434\n","Trainable params: 2,395,434\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1563/1563 [==============================] - 29s 18ms/step - loss: 1.5115 - accuracy: 0.4433 - val_loss: 1.1447 - val_accuracy: 0.5848\n","Epoch 2/10\n","1563/1563 [==============================] - 27s 17ms/step - loss: 1.0430 - accuracy: 0.6299 - val_loss: 0.9458 - val_accuracy: 0.6676\n","Epoch 3/10\n","1563/1563 [==============================] - 27s 17ms/step - loss: 0.8623 - accuracy: 0.6951 - val_loss: 0.7975 - val_accuracy: 0.7227\n","Epoch 4/10\n","1563/1563 [==============================] - 28s 18ms/step - loss: 0.7582 - accuracy: 0.7348 - val_loss: 0.7628 - val_accuracy: 0.7369\n","Epoch 5/10\n","1563/1563 [==============================] - 28s 18ms/step - loss: 0.6771 - accuracy: 0.7618 - val_loss: 0.7307 - val_accuracy: 0.7474\n","Epoch 6/10\n","1563/1563 [==============================] - 28s 18ms/step - loss: 0.6295 - accuracy: 0.7799 - val_loss: 0.6835 - val_accuracy: 0.7668\n","Epoch 7/10\n","1563/1563 [==============================] - 28s 18ms/step - loss: 0.5838 - accuracy: 0.7957 - val_loss: 0.7038 - val_accuracy: 0.7668\n","Epoch 8/10\n","1563/1563 [==============================] - 28s 18ms/step - loss: 0.5401 - accuracy: 0.8097 - val_loss: 0.6703 - val_accuracy: 0.7771\n","Epoch 9/10\n","1563/1563 [==============================] - 28s 18ms/step - loss: 0.5148 - accuracy: 0.8204 - val_loss: 0.6772 - val_accuracy: 0.7734\n","Epoch 10/10\n","1563/1563 [==============================] - 28s 18ms/step - loss: 0.4909 - accuracy: 0.8276 - val_loss: 0.6826 - val_accuracy: 0.7808\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f56d1764fd0>"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["score = model_5.evaluate(x_test, y_test, verbose = 0)\n","accuracy_D = score[1]\n","\n","print(('\\033[1mTest loss:\\033[0m {:.3f}').format(score[0]))\n","print(('\\033[1mTest accuracy:\\033[0m {:.3f}').format(accuracy_D))\n","print('\\n\\033[1mDid it work better?\\033[0m', accuracy_D > accuracy_C)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YEZvnODYNMEn","executionInfo":{"status":"ok","timestamp":1651592040849,"user_tz":-180,"elapsed":2374,"user":{"displayName":"יודית הלפרין","userId":"01188529069081813321"}},"outputId":"9ac00ccb-f97c-4ea4-9a72-cb5dedc18d56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mTest loss:\u001b[0m 0.683\n","\u001b[1mTest accuracy:\u001b[0m 0.781\n","\n","\u001b[1mDid it work better?\u001b[0m True\n"]}]},{"cell_type":"markdown","source":["**78% Accuracy!**"],"metadata":{"id":"IOKGngt_kEiv"}}]}